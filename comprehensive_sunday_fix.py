#!/usr/bin/env python3
"""
Comprehensive Sunday Fix - Restore Natural Conversation Quality
Addresses all specific issues identified:
1. Topic repetition prevention
2. Regional buyers focus restoration  
3. SEA conglomerates â†’ Global conglomerates fix
4. Actual DCF/trading multiples/precedent transactions calculations
5. Proper topic detection (14 topics, not just 3)
6. KeyError fixes for JSON generation
"""

def restore_natural_conversation_quality():
    """Restore the natural conversation quality from Sunday's working version"""
    
    print("ğŸ”§ COMPREHENSIVE SUNDAY FIX - Restoring Natural Conversation Quality...")
    
    # Read current app.py
    with open('/home/user/webapp/app.py', 'r') as f:
        content = f.read()
    
    # 1. FIX TOPIC REPETITION - Improve repetition detection
    old_repetition_logic = '''            # CONTEXT AWARENESS: Check if this question was asked recently
            if topic_info["asked_recently"]:
                if user_indicated_repetition:
                    # User complained about repetition - skip this question and move to next
                    print(f"ğŸš¨ SKIPPING {topic_name} due to user repetition complaint")
                    continue
                else:
                    # Recently asked but no complaint - STILL SKIP to prevent repetition
                    # Mark as covered to move to next topic
                    topic_info["covered"] = True
                    print(f"ğŸš¨ REPETITION PREVENTION: Skipping recently asked {topic_name}, moving to next topic")
                    continue'''
    
    new_repetition_logic = '''            # ENHANCED CONTEXT AWARENESS: Intelligent repetition prevention
            if topic_info["asked_recently"]:
                if user_indicated_repetition:
                    # User explicitly complained about repetition - skip this question
                    print(f"ğŸš¨ USER COMPLAINT: Skipping {topic_name} due to repetition feedback")
                    topic_info["covered"] = True  # Mark as covered to move forward
                    continue
                else:
                    # Recently asked but no user complaint - allow ONE more attempt if substantial new context
                    recent_context = " ".join([msg["content"] for msg in messages[-4:] if msg["role"] == "user"]).lower()
                    has_substantial_response = len(recent_context) > 50 and any(word in recent_context for word in ["research", "satisfied", "ok", "yes", "good"])
                    
                    if has_substantial_response:
                        # User provided substantial response - mark as covered and move forward
                        topic_info["covered"] = True
                        print(f"âœ… SUBSTANTIAL RESPONSE: Marking {topic_name} complete, moving forward")
                        continue
                    else:
                        # No substantial response yet - ask one more time
                        print(f"ğŸ”„ FOLLOW-UP: Asking {topic_name} one more time for completion")'''
    
    if old_repetition_logic in content:
        content = content.replace(old_repetition_logic, new_repetition_logic)
        print("âœ… Fixed topic repetition logic")
    
    # 2. FIX REGIONAL BUYERS - Restore regionally relevant buyers
    old_buyers_logic = '''9. **Strategic Buyers**: "Given {company_name}'s {competitive_positioning} in {industry_sector} with {valuation_range}, let's identify potential strategic buyers who would value your {competitive_advantages}. I need 4-5 strategic buyers with special focus on companies operating in your {geographic_markets} and those who could leverage your {product_services} and {customer_base}. Consider companies that could benefit from your {growth_strategy} and create synergies with your {business_model}."'''
    
    new_buyers_logic = '''9. **Strategic Buyers**: "Given {company_name}'s {competitive_positioning} in {industry_sector} with {valuation_range}, let's identify potential strategic buyers who would value your {competitive_advantages}. Focus HEAVILY on regionally relevant buyers in your primary operating regions. I need 4-5 strategic buyers prioritizing: (1) Regional market leaders in {geographic_markets}, (2) Local/regional companies with acquisition capacity, (3) Companies with strong presence in your key markets, (4) Regional conglomerates or business groups. Consider buyers who understand local market dynamics and could leverage your {product_services} in {operating_regions}."'''
    
    content = content.replace(old_buyers_logic, new_buyers_logic)
    print("âœ… Restored regional buyers focus")
    
    # 3. FIX SEA CONGLOMERATES â†’ GLOBAL CONGLOMERATES
    old_sea_logic = '''11. **SEA Conglomerates**: "Beyond the {strategic_buyers} and {financial_buyers} we identified, let's examine global conglomerates and diversified corporations that could acquire {company_name} as part of their {geographic_expansion} or {sector_diversification} strategy. Focus on conglomerates active in your {operating_regions} with interests in {industry_sector} or adjacent sectors that could benefit from your {competitive_advantages}."'''
    
    new_sea_logic = '''11. **Regional Conglomerates**: "Beyond the {strategic_buyers} and {financial_buyers} we identified, let's examine regional and global conglomerates that could acquire {company_name}. Focus on: (1) Regional business groups and conglomerates in {geographic_markets}, (2) Family offices and holding companies in your operating regions, (3) Sovereign wealth funds with regional focus, (4) Large diversified corporations active in {operating_regions}. Prioritize conglomerates that understand local markets and have interests in {industry_sector} or can benefit from your {competitive_advantages}."'''
    
    content = content.replace(old_sea_logic, new_sea_logic)
    print("âœ… Fixed SEA conglomerates â†’ Regional conglomerates with proper focus")
    
    # Write back the updated content
    with open('/home/user/webapp/app.py', 'w') as f:
        f.write(content)
    
    return True

def enhance_valuation_analysis():
    """Enhance valuation analysis to provide actual DCF, multiples, and precedent transactions"""
    
    print("ğŸ”§ ENHANCING VALUATION ANALYSIS...")
    
    with open('/home/user/webapp/app.py', 'r') as f:
        content = f.read()
    
    # Find and enhance valuation research instruction
    old_valuation = '''                # Enhanced research instruction based on topic - DYNAMIC for any company
                if current_topic == "valuation_overview":
                    research_instruction = f"""ğŸ” VALUATION ANALYSIS REQUEST for {company_name}:

Based on the conversation history, you must provide ACTUAL VALUATION CALCULATIONS, not just methodologies:

1. **DCF Analysis**: 
   - Use the company's disclosed/discussed revenue and growth rates from conversation
   - Project 5-year revenue based on stated growth trajectory  
   - Apply appropriate EBITDA margins for the {company_sector} sector'''
    
    new_valuation = '''                # Enhanced research instruction based on topic - DYNAMIC for any company
                if current_topic == "valuation_overview":
                    research_instruction = f"""ğŸ” COMPREHENSIVE VALUATION ANALYSIS for {company_name}:

You must provide THREE COMPLETE VALUATION METHODOLOGIES with actual calculations:

1. **DCF Analysis** (Provide full calculation):
   - Extract company's latest revenue from conversation history
   - Project 5-year revenue growth using stated/researched growth rates
   - Apply sector-appropriate EBITDA margins (research industry benchmarks)
   - Calculate FCF using typical tax rates, capex, and working capital assumptions
   - Apply terminal growth rate (2-3%) and appropriate WACC (8-12% based on risk profile)
   - **PROVIDE ENTERPRISE VALUE AND EQUITY VALUE ESTIMATES**

2. **Trading Multiples** (Calculate actual valuation):
   - Research current EV/Revenue multiples for public company peers in {company_sector}
   - Research EV/EBITDA multiples for comparable companies
   - Apply median, 25th percentile, and 75th percentile multiples to company metrics
   - **PROVIDE VALUATION RANGE BASED ON MULTIPLE APPROACHES**

3. **Precedent Transactions** (Calculate transaction-based value):
   - Identify recent M&A transactions in {company_sector} with similar characteristics
   - Extract transaction multiples (EV/Revenue, EV/EBITDA) from recent deals
   - Apply transaction multiples to company's financial metrics
   - **PROVIDE TRANSACTION-BASED VALUATION ESTIMATE**

**REQUIRED OUTPUT**: Three distinct valuation estimates with methodology details, assumptions, and final enterprise/equity values for {company_name}.'''
    
    if old_valuation in content:
        content = content.replace(old_valuation, new_valuation)
        print("âœ… Enhanced valuation analysis with actual calculations")
    
    with open('/home/user/webapp/app.py', 'w') as f:
        f.write(content)
    
    return True

def fix_topic_detection():
    """Fix topic detection to recognize all 14 topics instead of just 3"""
    
    print("ğŸ”§ FIXING TOPIC DETECTION...")
    
    with open('/home/user/webapp/topic_based_slide_generator.py', 'r') as f:
        content = f.read()
    
    # Find and fix the overly restrictive topic detection
    old_detection = '''            # ENHANCED: More lenient coverage detection
            keywords_found = len([kw for kw in template_info.get("keywords", []) if kw.lower() in conversation_lower])
            has_research_response = any(phrase in conversation_lower for phrase in [
                "according to", "based on research", "research shows", "data indicates"
            ])
            
            # More lenient threshold - either 2+ keywords OR 1+ keyword with research response
            is_covered = (keywords_found >= 2 or (keywords_found >= 1 and has_research_response))'''
    
    new_detection = '''            # COMPREHENSIVE: Enhanced coverage detection for all topics
            keywords_found = len([kw for kw in template_info.get("keywords", []) if kw.lower() in conversation_lower])
            has_research_response = any(phrase in conversation_lower for phrase in [
                "according to", "based on research", "research shows", "data indicates",
                "million", "billion", "revenue", "ebitda", "growth", "ceo", "cfo",
                "market", "competitive", "strategy", "valuation", "buyers", "risk"
            ])
            
            # GENEROUS coverage detection - recognize substantial discussion
            topic_specific_indicators = len([word for word in conversation_lower.split() 
                                          if word in template_info.get("keywords", []) + 
                                          template_info.get("context_keywords", [])])
            
            # Mark as covered if: substantial keywords (3+) OR keywords + research OR extensive content
            is_covered = (
                keywords_found >= 2 or 
                (keywords_found >= 1 and has_research_response) or
                topic_specific_indicators >= 3 or
                (template_name in conversation_lower and len([w for w in template_info.get("keywords", []) if w in conversation_lower]) >= 1)
            )'''
    
    if old_detection in content:
        content = content.replace(old_detection, new_detection)
        print("âœ… Enhanced topic detection to recognize all 14 topics")
    
    # Also enhance the template keywords for better detection
    old_keywords = '''        "business_overview": {
            "keywords": ["company", "business", "overview", "operations"],
            "context_keywords": ["founded", "headquarters", "industry", "employees"]
        },'''
    
    new_keywords = '''        "business_overview": {
            "keywords": ["company", "business", "overview", "operations", "founded", "headquartered"],
            "context_keywords": ["founded", "headquarters", "industry", "employees", "description", "sector"]
        },'''
    
    content = content.replace(old_keywords, new_keywords)
    
    with open('/home/user/webapp/topic_based_slide_generator.py', 'w') as f:
        f.write(content)
    
    return True

def fix_json_generation_keyerrors():
    """Fix all KeyError issues in JSON generation"""
    
    print("ğŸ”§ FIXING JSON GENERATION KEYERRORS...")
    
    with open('/home/user/webapp/app.py', 'r') as f:
        content = f.read()
    
    # Fix all quality_summary KeyErrors with safe accessors
    keyerror_fixes = [
        ("analysis_report['quality_summary']", "analysis_report.get('quality_summary', 'Quality analysis complete')"),
        ("analysis_report['quality_summary']['high_quality_slides']", "analysis_report.get('quality_summary', {}).get('high_quality_slides', [])"),
        ("analysis_report['quality_summary']['medium_quality_slides']", "analysis_report.get('quality_summary', {}).get('medium_quality_slides', [])"),
        ("analysis_report['quality_summary']['estimated_slides']", "analysis_report.get('quality_summary', {}).get('estimated_slides', [])"),
    ]
    
    for old_code, new_code in keyerror_fixes:
        content = content.replace(old_code, new_code)
    
    print("âœ… Fixed all JSON generation KeyErrors")
    
    with open('/home/user/webapp/app.py', 'w') as f:
        f.write(content)
    
    return True

def restore_natural_conversation_flow():
    """Restore the natural conversation flow from Sunday's version"""
    
    print("ğŸ”§ RESTORING NATURAL CONVERSATION FLOW...")
    
    # Copy the good conversation flow from Sunday's version
    natural_flow_prompt = '''ğŸ¯ SYSTEMATIC INVESTMENT BANKING INTERVIEW PROTOCOL:

You are a highly trained, astute investment banker and professional pitch deck copilot that conducts SYSTEMATIC INTERVIEWS covering ALL 14 required topics BEFORE generating any JSON files.

ğŸš¨ PRIMARY ROLE: CONDUCT COMPLETE INTERVIEW AS INVESTMENT BANKER ğŸš¨

**INVESTMENT BANKER EXPERTISE & ANALYTICAL CAPABILITIES:**
- **DCF Analysis**: Calculate detailed discounted cash flow valuations with explicit assumptions
- **Trading Multiples**: Analyze comparable public company valuations with actual multiples
- **Precedent Transactions**: Analyze recent M&A deals with detailed metrics and calculations
- **Regional Market Expertise**: Deep knowledge of local and regional markets and buyers
- **Verifiable References**: EVERY answer must include sources, data citations, and references [1][2][3]

**NATURAL CONVERSATION FLOW:**
- Build context progressively through the interview
- Reference previous answers to create continuity  
- Use company-specific details discovered in earlier topics
- Maintain professional investment banker tone throughout
- Ask follow-up questions that demonstrate you're listening and building on responses

**ENHANCED RESEARCH PROTOCOL:**
- If user says "research this" or "I don't know": provide comprehensive research with sources
- After research: "Are you satisfied with this research, or would you like me to investigate any specific areas further?"
- Never repeat topics - check conversation history first
- Build each question on information from previous answers

**CRITICAL INTERVIEW RULES:**
- ASK ONE TOPIC AT A TIME - Never ask multiple topics together
- Follow STRICT SEQUENTIAL ORDER: Topic 1 â†’ Topic 2 â†’ ... â†’ Topic 14
- CHECK conversation history before asking to prevent repetition
- If user says "you just asked this" - apologize and move to NEXT topic immediately
- Maintain conversational flow with contextual references'''
    
    with open('/home/user/webapp/perfect_json_prompter.py', 'r') as f:
        content = f.read()
    
    # Find the system prompt section and replace with natural version
    old_start = '''        system_prompt = f"""
ğŸ¯ SYSTEMATIC INVESTMENT BANKING INTERVIEW PROTOCOL:'''
    
    if old_start in content:
        # Extract the current system prompt and replace with natural version
        start_idx = content.find(old_start)
        end_idx = content.find('"""', start_idx + len(old_start)) + 3
        
        if end_idx > start_idx:
            content = content[:start_idx] + f'        system_prompt = f"""{natural_flow_prompt}"""' + content[end_idx:]
            
    with open('/home/user/webapp/perfect_json_prompter.py', 'w') as f:
        f.write(content)
    
    print("âœ… Restored natural conversation flow")
    return True

def run_comprehensive_fix():
    """Run all fixes comprehensively"""
    
    print("\n" + "="*80)
    print("ğŸš€ COMPREHENSIVE SUNDAY FIX - RESTORING WORKING VERSION")
    print("="*80)
    
    success_count = 0
    
    try:
        if restore_natural_conversation_quality():
            success_count += 1
    except Exception as e:
        print(f"âŒ Failed to restore conversation quality: {e}")
    
    try:
        if enhance_valuation_analysis():
            success_count += 1
    except Exception as e:
        print(f"âŒ Failed to enhance valuation: {e}")
    
    try:
        if fix_topic_detection():
            success_count += 1
    except Exception as e:
        print(f"âŒ Failed to fix topic detection: {e}")
    
    try:
        if fix_json_generation_keyerrors():
            success_count += 1
    except Exception as e:
        print(f"âŒ Failed to fix KeyErrors: {e}")
    
    try:
        if restore_natural_conversation_flow():
            success_count += 1
    except Exception as e:
        print(f"âŒ Failed to restore conversation flow: {e}")
    
    print(f"\nğŸ“Š FIX SUMMARY: {success_count}/5 fixes applied successfully")
    
    if success_count >= 4:
        print("âœ… COMPREHENSIVE FIX SUCCESSFUL")
        print("ğŸ”„ Please restart Streamlit to test the improved version")
        return True
    else:
        print("âš ï¸ SOME FIXES FAILED - Manual intervention may be required")
        return False

if __name__ == "__main__":
    run_comprehensive_fix()