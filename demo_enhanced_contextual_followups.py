#!/usr/bin/env python3

"""
DEMONSTRATION: Enhanced Contextual Follow-ups with Fact-Checking
Shows how the enhanced system improves existing functionality without breaking it
"""

from enhanced_conversation_manager import enhanced_manager
from collections import deque

def simulate_enhanced_contextual_flow():
    """Demonstrate enhanced contextual follow-up capabilities"""
    
    print("ðŸŽ¯ ENHANCED CONTEXTUAL FOLLOW-UPS DEMONSTRATION")
    print("=" * 60)
    print("Shows how enhancement IMPROVES existing functionality without breaking it\n")
    
    # Mock session state
    session_state = {
        'messages': [],
        'company_name': 'TechCorp',
        'api_key': 'test',
        'api_service': 'claude',
        'model': 'claude-3-5-sonnet'
    }
    
    # Initialize enhanced system
    enhanced_manager.init_session_state(session_state)
    
    # Test scenarios showing partial information handling
    scenarios = [
        {
            "topic": "historical_financial_performance",
            "user_input": "We had $50M revenue last year",
            "description": "User provides revenue only (missing margins & growth)"
        },
        {
            "topic": "historical_financial_performance", 
            "user_input": "Revenue was $50M with 25% EBITDA margins",
            "description": "User provides revenue & margins (missing growth)"
        },
        {
            "topic": "historical_financial_performance",
            "user_input": "We generated $50M revenue in 2024, up 40% from 2023, with 25% EBITDA margins",
            "description": "User provides complete information (all components)"
        },
        {
            "topic": "management_team",
            "user_input": "Sarah Johnson is our CEO",
            "description": "User mentions CEO only (missing CFO & backgrounds)"
        },
        {
            "topic": "management_team",
            "user_input": "Sarah Johnson is our CEO, previously at Goldman Sachs. Mike Chen is our CFO with 15 years experience.",
            "description": "User provides comprehensive management info"
        }
    ]
    
    for i, scenario in enumerate(scenarios, 1):
        print(f"ðŸ“‹ Scenario {i}: {scenario['description']}")
        print(f"   Topic: {scenario['topic']}")
        print(f"   User Input: \"{scenario['user_input']}\"")
        
        # 1. EXISTING ALIYA LOGIC (simulate your actual contextual detection)
        existing_result = simulate_existing_contextual_logic(scenario['topic'], scenario['user_input'])
        
        print(f"   ðŸ”§ Existing Aliya Logic:")
        print(f"      Needs More Info: {existing_result['needs_more_info']}")
        if existing_result['needs_more_info']:
            print(f"      Missing Parts: {existing_result['missing_parts']}")
            print(f"      Follow-up: \"{existing_result['contextual_followup']}\"")
        
        # 2. ENHANCED INTELLIGENCE (adds on top of existing logic)
        enhanced_result = simulate_enhanced_logic(scenario['topic'], scenario['user_input'], session_state)
        
        print(f"   ðŸš€ Enhanced Intelligence:")
        print(f"      User Intent: {enhanced_result['intent']}")
        print(f"      Topic Satisfaction: {enhanced_result['satisfaction']:.2f} ({enhanced_result['satisfaction']:.0%})")
        print(f"      Should Follow-up: {enhanced_result['should_followup']}")
        print(f"      Enhanced Context: {enhanced_result['enhanced_context']}")
        
        # 3. COMBINED RESULT (how they work together)
        if existing_result['needs_more_info'] or enhanced_result['should_followup']:
            final_followup = existing_result['contextual_followup'] if existing_result['needs_more_info'] else enhanced_result['suggested_followup']
            print(f"   âœ¨ FINAL RESULT: Follow-up question will be asked")
            print(f"      Question: \"{final_followup}\"")
        else:
            print(f"   âœ… FINAL RESULT: Information complete - no follow-up needed")
        
        print()

def simulate_existing_contextual_logic(topic, user_response):
    """Simulate your existing contextual follow-up logic (UNCHANGED)"""
    
    needs_more_info = False
    missing_parts = []
    contextual_followup = ""
    
    # YOUR EXACT EXISTING LOGIC (copied from app.py)
    if topic == "historical_financial_performance" and len(user_response) > 10:
        has_revenue = any(word in user_response.lower() for word in ["revenue", "sales", "million", "billion", "$"])
        has_margins = any(word in user_response.lower() for word in ["margin", "ebitda", "profit", "%", "percentage"])
        has_growth = any(word in user_response.lower() for word in ["growth", "year", "2023", "2024", "increased"])
        
        if not (has_revenue and has_margins and has_growth):
            needs_more_info = True
            if not has_revenue: missing_parts.append("revenue figures")
            if not has_margins: missing_parts.append("EBITDA margins")  
            if not has_growth: missing_parts.append("growth rates")
            contextual_followup = f"Thanks for that information! To complete the financial analysis, I additionally need {' and '.join(missing_parts)}. Do you have this data, or should I research it?"
    
    elif topic == "management_team" and len(user_response) > 10:
        has_ceo = any(word in user_response.lower() for word in ["ceo", "chief executive"])
        has_cfo = any(word in user_response.lower() for word in ["cfo", "chief financial"])
        has_backgrounds = any(word in user_response.lower() for word in ["experience", "background", "previously", "worked", "founded"])
        
        if not (has_ceo and has_cfo and has_backgrounds):
            needs_more_info = True
            if not has_ceo: missing_parts.append("CEO information")
            if not has_cfo: missing_parts.append("CFO details")
            if not has_backgrounds: missing_parts.append("executive backgrounds")
            contextual_followup = f"Good start on the management team! I additionally need {' and '.join(missing_parts)} for the pitch deck. Do you have this information, or should I research it?"
    
    return {
        'needs_more_info': needs_more_info,
        'missing_parts': missing_parts,
        'contextual_followup': contextual_followup
    }

def simulate_enhanced_logic(topic, user_response, session_state):
    """Simulate enhanced intelligence layer"""
    
    # Classify user intent
    intent = enhanced_manager.classify_user_intent(user_response)
    
    # Assess topic satisfaction
    satisfaction = enhanced_manager.assess_topic_satisfaction(topic, user_response)
    
    # Determine if enhancement suggests follow-up
    should_followup = satisfaction < 0.6  # Enhancement threshold
    
    # Enhanced context for LLM
    enhanced_context = f"User provided {len(user_response.split())} words with {satisfaction:.0%} topic satisfaction"
    
    # Enhanced follow-up suggestion
    suggested_followup = ""
    if should_followup and satisfaction < 0.4:
        suggested_followup = f"I notice your response covers some aspects of {topic.replace('_', ' ')}, but could you provide more specific details or would you prefer I research additional information for you?"
    
    return {
        'intent': intent,
        'satisfaction': satisfaction,
        'should_followup': should_followup,
        'enhanced_context': enhanced_context,
        'suggested_followup': suggested_followup
    }

def demonstrate_fact_checking_enhancement():
    """Show how fact-checking is enhanced with better context"""
    
    print(f"\nðŸ” FACT-CHECKING ENHANCEMENT DEMONSTRATION")
    print("-" * 50)
    
    fact_check_scenarios = [
        {
            "user_claim": "We have 90% market share in fintech",
            "context": "Small startup with $1M revenue",
            "enhanced_verification": "Cross-reference market share claim with revenue scale and industry data"
        },
        {
            "user_claim": "Our EBITDA margin is 50%",
            "context": "SaaS company in growth phase",
            "enhanced_verification": "Verify 50% EBITDA margin against SaaS industry benchmarks and growth stage"
        },
        {
            "user_claim": "We're valued at $1 billion",
            "context": "Series A company with $10M revenue",
            "enhanced_verification": "Check 100x revenue multiple against comparable company valuations"
        }
    ]
    
    for scenario in fact_check_scenarios:
        print(f"ðŸ“Š Claim: \"{scenario['user_claim']}\"")
        print(f"   Context: {scenario['context']}")
        print(f"   Enhanced Verification: {scenario['enhanced_verification']}")
        print(f"   ðŸ¤– LLM Prompt Enhancement:")
        
        enhanced_prompt = f"""FACT-CHECK the user's claim: "{scenario['user_claim']}"
        
CONTEXT: {scenario['context']}
VERIFICATION FOCUS: {scenario['enhanced_verification']}
CONVERSATION MEMORY: [Previous relevant exchanges]

RESPONSE FORMAT:
1. VERIFICATION: "That's reasonable" OR "Actually, there may be an issue..."
2. ANALYSIS: Provide context and industry benchmarks
3. FOLLOW-UP: Ask specific clarifying questions
4. RESEARCH OPTION: "Would you like me to research industry comparables?"
"""
        print(f"      System prompt includes conversation context and verification focus")
        print()

if __name__ == "__main__":
    simulate_enhanced_contextual_flow()
    demonstrate_fact_checking_enhancement()
    
    print("=" * 60)
    print("ðŸŽ¯ KEY TAKEAWAYS:")
    print("âœ… Existing contextual follow-up logic is 100% PRESERVED")
    print("âœ… Enhanced intelligence adds ADDITIONAL smart detection") 
    print("âœ… Fact-checking gets better context and conversation memory")
    print("âœ… LLM prompts are enhanced with conversation history")
    print("âœ… Research options are ALWAYS offered in follow-ups")
    print("âœ… All improvements work ON TOP OF existing functionality")
    print("\nðŸš€ YOUR CONTEXTUAL FOLLOW-UPS ARE BETTER THAN EVER!")